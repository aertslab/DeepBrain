{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process cDNA and genomic DNA MPRA reads for microglia lentiMPRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mkdir -p {path-to-dir}\n",
    "cd {path-to-dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p 00.FastQC 01.cleaned_reads 02.sequencing_saturation 10.bc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_raw={path-to-data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 00.FastQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "module load FastQC/0.11.9-Java-11\n",
    "fastqc -t 10  ${path_raw}MGE*.fastq.gz -o 00.FastQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.Cleaned Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGE__6369dc__PCR_2_cDNA_BV2_microglia_75_l_S13_L001_R1_001.fastq.gz\n",
      "MGE__9b6969__PCR_2_cDNA_BV2_microglia_100_l_S12_L001_R1_001.fastq.gz\n",
      "MGE__bb4620__PCR_2_cDNA_BV2_microglia_150_l_S11_L001_R1_001.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "# for i in $(ls ${path_raw}MGE*1_R1_001.fastq.gz)\n",
    "# do\n",
    "# file=${i##*/}\n",
    "# echo $file\n",
    "# R1=$(echo ${i%_L00*}* | awk '{print $1, $4}')\n",
    "# cat $R1 > 01.cleaned_reads/${file%_S*_*}_R1_001.fastq.gz\n",
    "# R2=$(echo ${i%_L00*}* | awk '{print $3, $6}')\n",
    "# cat $R2 > 01.cleaned_reads/${file%_S*_*}_R3_001.fastq.gz\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls $path_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.1.Merge reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read 1 and read 2 are overlapping. They both contain the full sequence of the MPRA barcode. We use fastp to merge R1 and R2 to obtain a consensus sequence with higher quality score than each individual read. Further on, we still process the unmerged read 2 sequences to recover some extra barcodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "module load fastp/0.23.2-GCC-10.3.0\n",
    "for i in $(ls ${path_raw}*_R1_001.fastq.gz)\n",
    "do\n",
    "file=${i##*/}\n",
    "fastp -m -h /dev/null/fastp.html -j /dev/null/fastp.json -w 8 \\\n",
    "      --merged_out 01.cleaned_reads/${file%_R*_*}_merged.fastq.gz \\\n",
    "      -o 01.cleaned_reads/${file%_R*_*}_R1_unmerged.fastq.gz -O 01.cleaned_reads/${file%_R*_*}_R2_unmerged.fastq.gz \\\n",
    "      -i $i -I ${i%R1_*}R2_001.fastq.gz\n",
    "rm 01.cleaned_reads/${file%_R*_*}_R1_unmerged.fastq.gz\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 01.2.Cutadapt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract MPRA barcodes from merged and unmerged R2 reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "module load cutadapt/4.2\n",
    "module --ignore-cache load SeqKit/2.4.0\n",
    "\n",
    "## On merged reads\n",
    "for i in $(ls 01.cleaned_reads/*_merged.fastq.gz)\n",
    "do\n",
    "cutadapt -g TGCCTACGGACCGGCGCGCCGATC...TGTCTGCGAGGGCCAGC -e 0.10 -l 17 -m 17 -j 10 --discard-untrimmed \\\n",
    "         -o ${i%%.fastq.*}_trimmed.fastq.gz \\\n",
    "         $i\n",
    "rm $i\n",
    "done\n",
    "\n",
    "## On R2 reads\n",
    "for i in $(ls 01.cleaned_reads/*R2_unmerged.fastq.gz)\n",
    "do\n",
    "file=${i##*/}\n",
    "cutadapt -g CTGGCCCTCGCAGACA...GATCGGCGCGCCGGTCC -e 0.15 -l 17 -m 17 -j 10 --discard-untrimmed \\\n",
    "         $i | \\\n",
    "         seqkit seq -r -p -o 01.cleaned_reads/${file%%.*}_trimmed.fastq.gz\n",
    "rm $i\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.3.Q30 filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out reads with average phred score < 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "module load fastp/0.23.2-GCC-10.3.0\n",
    "for i in $(ls 01.cleaned_reads/*_trimmed.fastq.gz)\n",
    "do\n",
    "file=${i##*/}\n",
    "fastp -e 30 -h /dev/null/fastp.html -j /dev/null/fastp.json -w 8 \\\n",
    "      -o 01.cleaned_reads/${file%%.*}_q30.fastq.gz \\\n",
    "      -i $i\n",
    "rm $i\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine BCs from merged and unmerged fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in $(ls 01.cleaned_reads/*_merged_trimmed_q30.fastq.gz)\n",
    "do\n",
    " cat ${i%_merged_*}*merged_trimmed_q30.fastq.gz > ${i%_merged_*}_combined.fastq.gz\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.4.Print states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load mawk/1.3.4-20230525-GCCcore-10.3.0\n",
    "> stats.txt\n",
    "for i in $(ls 01.cleaned_reads/*_combined.fastq.gz)\n",
    "do \n",
    "file=${i#*/}\n",
    "zcat $i | \\\n",
    "mawk -v 'OFS=\\t' -v filename=\"${file%_combined*}\" '\n",
    "{\n",
    "    # Only look at each sequence line\n",
    "    if (NR%4==2) {\n",
    "        read = $1\n",
    "        # Add 1 to current read counter.\n",
    "        counts[read] += 1\n",
    "        # Count total number of reads seen so far.\n",
    "        total_reads += 1\n",
    "    }\n",
    "}\n",
    "\n",
    "END {\n",
    "    for (read in counts) {\n",
    "        if (counts[read] > max) {\n",
    "            max = counts[read]\n",
    "            max_readname = read\n",
    "        }\n",
    "    }\n",
    "    unique_reads = length(counts)\n",
    "    print filename, total_reads, unique_reads, (unique_reads * 100 / total_reads) \"%\", max_readname, max, (max * 100 / total_reads) \"%\"\n",
    "}\n",
    "' \\\n",
    ">> stats.txt\n",
    "echo ${file%_combined*} \"done\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk 'BEGIN {printf \"Sample\\t#_reads\\t#_unique_reads\\t%_unique_reads\\tTop_sequence\\t#_reads_top_sequence\\t%_top_sequence\\n\"} {print}'  stats.txt | column -t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make BC count matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract DNA sequences from fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in $(ls 01.cleaned_reads/*_combined.fastq.gz)\n",
    "do \n",
    "file=${i#*/}\n",
    "zcat $i | sed -n '2~4p' > 10.bc_count/${file%%.*}.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate BC count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel \\\n",
    "\"cat 10.bc_count/{}_combined.txt | sort | uniq -c | awk -F \\\" \\\" '{print \\$2\\\"\\t\\\"\\$1}' \\\n",
    "   > 10.bc_count/{}_count.txt\" ::: $(ls 10.bc_count/*_combined.txt | awk -F\"/|_combined\" '{print $2}') 2>/dev/null\n",
    "\n",
    "# Count number of unique BC per sample\n",
    "for i in $(ls 10.bc_count/*_count.txt)\n",
    "do\n",
    "echo $i && cat $i | wc -l\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign BC to enhancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign BC to enhancers\n",
    "EnhBC={path-to-enh-BC-assignment}\n",
    "parallel \\\n",
    "\"awk -F '\\t' -v OFS='\\t' 'FNR==NR{a[\\$2]=\\$1 FS \\$2;next}{ print a[\\$1],\\$2}' \\\n",
    "   <( zcat $EnhBC ) \\\n",
    "   <( cat 10.bc_count/{}_count.txt ) \\\n",
    "   | awk -F '\\t' '{if (\\$1) print \\$0;}' \\\n",
    "   > 10.bc_count/{}_count_final.txt\" ::: $(ls 10.bc_count/*_combined.txt | awk -F\"/|_combined\" '{print $2}') 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in $(ls 10.bc_count/*_count_final.txt)\n",
    "do \n",
    "file=${i#*/}\n",
    "middleBC=$(($(awk '{print $1}' $i | sort | uniq -c | wc -l)/2))\n",
    "middleR=$(($(cat $i | wc -l)/2))\n",
    "echo ${file}\n",
    "echo \"Number of BC associated to an enhancer: \" $(cat $i | wc -l)\n",
    "echo \"Enhancer coverage: \" $(awk '{print $1}' $i | sort | uniq -c | wc -l)\n",
    "echo \"Median number of BCs per enhancer: \" $(awk '{print $1}' $i | sort | uniq -c | awk '{print $1}' | sort -g | sed -n ${middleBC}p)\n",
    "echo \"Median number of reads per BC: \" $(awk '{print $NF}' $i | sort -g | sed -n ${middleR}p)\n",
    "echo \"Number of Neg_Ctrl BC: \" $(grep 'Shuffle' $i | wc -l)\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "export LC_ALL=C\n",
    "for file in 10.bc_count/*_combined.txt\n",
    "do\n",
    "file_name=`basename ${file}`\n",
    "file_tag=${file_name%.txt}\n",
    "echo ${file_name}\n",
    "nreads=$(cat $file | wc -l)\n",
    "if test $nreads -gt 10000000\n",
    "then\n",
    "        increment=$(($nreads / 50))\n",
    "else\n",
    "        increment=200000\n",
    "fi\n",
    "    for i in $(seq 0 $increment $nreads)\n",
    "    do\n",
    "    # Print number of total and unique reads for every subsamples\n",
    "    echo \"echo $i \\$(shuf -n $(($i)) $file | sort -u | wc -l) >> 02.sequencing_saturation/${file_tag}_sat.txt\" \\\n",
    "    >> 02.sequencing_saturation/${file_tag}_parallel.txt\n",
    "    done\n",
    "cat 02.sequencing_saturation/${file_tag}_parallel.txt | parallel -j 16\n",
    "# Put values in numerical order\n",
    "cat  02.sequencing_saturation/${file_tag}_sat.txt | sort -g > 02.sequencing_saturation/${file_tag}_satsort.txt && mv 02.sequencing_saturation/${file_tag}_satsort.txt 02.sequencing_saturation/${file_tag}_sat.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load Python/3.7.4-GCCcore-6.4.0\n",
    "path_scripts={path-to-script}\n",
    "nfiles=$(ls 02.sequencing_saturation/*_sat.txt | wc -l)\n",
    "nrows=$(( ($nfiles + 2) / 3 ))\n",
    "${path_scripts}plot_saturation.py -ssd 02.sequencing_saturation -r _combined_sat.txt --ncol 3 --nrow $nrows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash (ipykernel)",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
